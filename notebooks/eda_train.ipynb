{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Gaza FIRMS: Fire vs Explosion â€” EDA & Training\n",
        "This notebook loads FIRMS CSVs, engineers features per grid/time window, and trains a RandomForest baseline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "from pathlib import Path\n",
        "import sys\n",
        "sys.path.append(str(Path('..').resolve()))\n",
        "from model.utils import extract_features_from_sequence, vectorize_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "viirs = pd.read_csv('../hotspots_viirs.csv', comment='#')\n",
        "modis = pd.read_csv('../hotspots_modis.csv', comment='#')\n",
        "df = pd.concat([viirs.assign(model='viirs'), modis.assign(model='modis')], ignore_index=True)\n",
        "df['timestamp'] = pd.to_datetime(df['acq_date'].astype(str) + ' ' + df['acq_time'].astype(str).str.zfill(4), format='%Y-%m-%d %H%M')\n",
        "df = df.dropna(subset=['timestamp','latitude','longitude'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create grid/time buckets\n",
        "def grid_key(lat, lon):\n",
        "    return (round(float(lat) * 100) / 100.0, round(float(lon) * 100) / 100.0)\n",
        "\n",
        "df['grid'] = df.apply(lambda r: grid_key(r['latitude'], r['longitude']), axis=1)\n",
        "window_minutes = 180\n",
        "df['bucket'] = df['timestamp'].dt.floor(f'{window_minutes}T')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate sequences and build features\n",
        "frp_col = 'frp' if 'frp' in df.columns else None\n",
        "groups = []\n",
        "features = []\n",
        "for (gcell, gbuck), g in df.groupby(['grid','bucket']):\n",
        "    g = g.sort_values('timestamp')\n",
        "    frps = list(g[frp_col]) if frp_col else [0.0] * len(g)\n",
        "    groups.append((gcell, gbuck))\n",
        "    features.append(extract_features_from_sequence(frps))\n",
        "X, keys = vectorize_features(features)\n",
        "len(X), keys[:3], X[:1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Labels\n",
        "For an initial experiment, you can construct weak labels using heuristics or external events. Replace this section with real labels when available.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Weak labels example: label as 'explosion' if sharp spike heuristic, else 'fire'\n",
        "y = []\n",
        "for fd in features:\n",
        "    is_explosion = (fd['rise'] > 0.6 * fd['max_frp']) and (fd['decay'] > 0.6 * fd['max_frp'])\n",
        "    y.append('explosion' if is_explosion else 'fire')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "clf = RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42, class_weight='balanced_subsample')\n",
        "clf.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model\n",
        "Path('../model').mkdir(parents=True, exist_ok=True)\n",
        "joblib.dump(clf, '../model/model_rf.pkl')\n",
        "'Saved to ../model/model_rf.pkl'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick time-series visualization for a few cells\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "example = df.groupby('grid').apply(lambda g: g.sort_values('timestamp')).head(500)\n",
        "for grid, g in example.groupby('grid'):\n",
        "    if 'frp' in g.columns and not g['frp'].isna().all():\n",
        "        plt.figure(figsize=(8,3))\n",
        "        plt.plot(g['timestamp'], g['frp'], marker='o', linestyle='-')\n",
        "        plt.title(f'Grid {grid} FRP over time')\n",
        "        plt.xlabel('Time'); plt.ylabel('FRP')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Event clustering (DBSCAN) and event-level features\n",
        "from src.pipeline.events import cluster_events, aggregate_event_features\n",
        "\n",
        "df_seq = df.copy()\n",
        "labels = cluster_events(df_seq)\n",
        "events = aggregate_event_features(df_seq, labels, frp_col='frp', timestamp_col='timestamp')\n",
        "print(events.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train RF on event features (weak labels placeholder)\n",
        "from src.modeling.trainers import train_random_forest, save_model\n",
        "\n",
        "# Weak labels based on spike shape\n",
        "y = []\n",
        "for _, r in events.iterrows():\n",
        "    is_explosion = (r['max_frp'] >= (events['max_frp'].median() or 0)) and (r['duration_hours'] <= 3)\n",
        "    y.append('explosion' if is_explosion else 'fire')\n",
        "\n",
        "features_cols = ['max_frp','mean_frp','std_frp','duration_hours','count']\n",
        "X = events[features_cols].fillna(0.0).values\n",
        "clf, report = train_random_forest(X, np.array(y))\n",
        "print(report['explosion'])\n",
        "\n",
        "from pathlib import Path\n",
        "Path('../model').mkdir(parents=True, exist_ok=True)\n",
        "save_model(clf, '../model/model_rf.pkl')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
